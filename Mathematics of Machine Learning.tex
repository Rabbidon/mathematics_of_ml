\documentclass{article}
\usepackage{enumitem}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

\newcommand{\chapternumber}{2}
\title{Mathematics for Machine Learning - Questions and Solutions}
\author{Edwin Fennell}
\date{}
\newenvironment{QandA}{\begin{enumerate}[label=\chapternumber.\arabic*]\bfseries\boldmath}
	{\end{enumerate}}
\newenvironment{answered}{\par\bigskip\normalfont\unboldmath}{}
\usepackage{lipsum}
\pagestyle{empty}
\begin{document}
	\maketitle
	
	Note - I'm not going to write out the questions here since they are very, very inefficiently posed and no way am I going to TeX all of that.
	
	\noindent%
	\begin{QandA}
		\item
		\begin{answered}
			a. In order to show that this constitutes a group, we need to show four things:
			\begin{itemize}
				\item Closure - if $a,b\in\mathbb{R}$ then clearly $ab+a+b\in\mathbb{R}$.
				Now, suppose that $ab + a + b=-1$. This rearranges to
				\[a(b+1)=-(b+1)\]
				or 
				\[(a+1)(b+1)=0\]
				Therefore if neither $a$ nor $b$ is equal to -1, $a*b$ also cannot be equal to -1, and therefore * is a valid group operation on $\mathbb{R}\backslash\{-1\}$.
				\item Identity - our identity is 0 since for any $a\in\mathbb{R}\backslash\{-1\}$ we have
				\[a*0 = a\cdot0 + 0 + a = a\]
				\item Inverse - given a fixed $a\in\mathbb{R}\backslash\{-1\}$ we want to solve for $x$ in the following:
				\[a*x = ax + x + a = 0\]
				we rearrange to get
				\[x = \frac{-a}{a+1}\]
				Therefore all elements in $\mathbb{R}\backslash\{-1\}$ have inverses under *
				\item Associativity - we consider the respective values of $(a*b)*c$ and $a*(b*c)$ for arbitrary $a,b,c\in\mathbb{R}\backslash\{-1\}$:
				\[(a*b)*c = (a*b)c + a*b + c = abc + ac + bc + ab + a + b + c\]
				\[(a*(b*c) = a(b*c) + b*c + a = abc + ac + bc + ab + a + b + c\]
				and so we have associativity.
						
			\end{itemize}
				
				Now we need to show that the resulting group is Abelian, but this is clear from the definition of * being completely symmetric in its two operands.
				
				\qed
				
				b. Conveniently, from our proof of associativity we know immediately that
				\[3*x*x = 3x^2 + 3x + 3x + x^2 + x + x + 3 = 4x^2 + 8x + 3\]
				Therefore we need to solve $4x^2 + 8x + 3 = 15$, or rather
				\[4x^2 + 8x - 12 = 4(x^2 + 2x -3) = 4(x+3)(x-1)+0\]
				From this we see that the solutions are exactly $x=1,x=-3$
		\end{answered}
		
		\item
		\begin{answered}
			a. We need to show the four group axioms:
			\begin{itemize}
				\item Closure - By definiton of $\oplus$ the result of its application is a congruence class mod $n$. (Well-posedness is another matter but that isn't asked for here).
				\item Identity - the identity is $\bar{0}$ since
				\[\forall a\in\mathbb{Z}, \bar{a} \oplus \bar{0} = \overline{(a + 0)} = \bar{a}\]
				\item Inverses - the inverse of $\bar{a}$ for any $a\in\mathbb{Z}$ is $\overline{-a}$:
				\[\forall a\in\mathbb{Z}, \bar{a} \oplus \overline{-a} = \overline{(a-a)} = \bar{0}\]
				\item Associativity - we have
				\[\forall a,b,c\in \mathbb{Z}, (\bar{a} \oplus \overline{b})\oplus \overline{c} = \overline{(a+b)}\oplus \overline{c} = \overline{a+b+c}\]
				and also
				\[\forall a,b,c\in \mathbb{Z}, \bar{a} \oplus (\overline{b}\oplus \overline{c}) = \overline{a} \oplus \overline{(b+c)} = \overline{a+b+c}\]
				and so we have associativity. Assuming that the operator $\oplus$ is well-defined, this more or less comes down to "addition is associative".
			\end{itemize}
			Therefore $(\mathbb{Z}_n,\oplus)$ is indeed a group.
			
			b. I'm not going to write out the multiplication table for $\mathbb{Z}_5\backslash\{\overline{0}\}$. I will show that this is a group when I prove the general case in part d of this question. Assuming that it is a group, it is clearly Abelian from the symmetric nature of $\otimes$.
			
			c. Again, I'll use the result from part d. 8 is composite so this is not a group.
			
			d. Suppose that $n$ is composite. Then $\exists$ $a$,$b$ s.t. $1<a,b<n$ and $a\cdot b=n$. Therefore we have 
			\[\overline{a}\otimes\overline{b}=\overline{n}=\overline{0}\]
			Therefore $\mathbb{Z}_n\backslash\{\overline{0}\}$ is not a group since it fails the requirement of closure.
			
			Now, if $n$ is instead prime, then $\mathbb{Z}_n\backslash\{\overline{0}\}$ is a group - we will show this by verifying the group axioms.
			\begin{itemize}
				\item Closure - suppose that $a,b\in\mathbb{Z}\backslash\{\overline{0}\}$. Now, suppose that
				\[ab\equiv 0 \mod{n}\]
				Then $ab=kn$ for some $k\in \mathbb{Z}$. Since $n$ is prime, $a$ and $n$ are coprime, and therefore by Bezout's theorem, $\exists u,v\in\mathbb{Z}$ s.t.
				\[ua+vn=1\]
				Therefore
				\[b = b\cdot 1 = b(ua+vn) = ab\cdot u + bvn = (uk+bv)n\]
				and so we find that $b$ is a multiple of $n$. This is a contradiction since $b\in\mathbb{Z}\backslash\{\overline{0}\}$. Therefore $ab\not\equiv 0 \mod{n}$ and we have 
				\[\overline{a},\overline{b}\neq\overline{0}\implies\overline{ab}\neq\overline{0}\]
				and so we have closure
				\item Identity - the identity is trivially $\overline{1}$
				\item Inverse - for any $\overline{a}\neq\overline{0}$ we have that $a$ and $n$ are coprime. By Bezout's theorem we know that $\exists u,v\in\mathbb{Z}$ s.t.
				\[ua+vn=1\]
				Therefore
				\[\overline{a}\otimes\overline{u}=\overline{au}=\overline{(1-vn)}=\overline{1}\]
				and so we have constructed an inverse for $\overline{a}$
				\item Associativity - exactly the same proof as in part a. Essentially "multiplication is associative".
			\end{itemize}
			Therefore $(\mathbb{Z}_n,\otimes)$ is indeed a group.
		\end{answered}
		
		\item
		\begin{answered}
			Let's check the four group requirements:
			\begin{itemize}
				\item Closure - $\forall x_1,y_1,z_1,x_2,y_2,z_2\in\mathbb{R}$ we have
				\[
				\begin{pmatrix}
					1 & x_1 & z_1 \\ 0 & 1 & y_1 \\ 0 & 0 & 1
				\end{pmatrix}
				\cdot
				\begin{pmatrix}
					1 & x_2 & z_2 \\ 0 & 1 & y_2 \\ 0 & 0 & 1
				\end{pmatrix}
				=
				\begin{pmatrix}
					1 & x_1+x_2 & x_1y_2+z_1+z_2 \\ 0 & 1 & y_1+y_2 \\ 0 & 0 & 1
				\end{pmatrix}
				\]
				so we have closure
				\item Identity - from the above calculation (or simply by knowing what the identity matrix is) we see that 
				\[
				\begin{pmatrix}
					1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1
				\end{pmatrix}
				\in
				\mathcal{G}\]
				and acts as the identity.
				\item Inverses - we see that $\forall x,y,z\in\mathbb{R}$ we have
				\[
				\begin{pmatrix}
					1 & x_1 & z_1 \\ 0 & 1 & y_1 \\ 0 & 0 & 1
				\end{pmatrix}
				\cdot
				\begin{pmatrix}
					1 & -x_1 & x_1y_1-z_1 \\ 0 & 1 & -y_1 \\ 0 & 0 & 1
				\end{pmatrix}
				=
				\begin{pmatrix}
					1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & 0 & 1
				\end{pmatrix}
				\]
				\item Associativity - we can just show this manually. Let
				\[x_1,y_1,z_1,x_2,y_2,z_2,x_3,y_3,z_3\in\mathbb{R}\]
				Then 
				\[
				\left(
				\begin{pmatrix}
					1 & x_1 & z_1 \\ 0 & 1 & y_1 \\ 0 & 0 & 1
				\end{pmatrix}
				\cdot
				\begin{pmatrix}
					1 & x_2 & z_2 \\ 0 & 1 & y_2 \\ 0 & 0 & 1
				\end{pmatrix}
				\right)
				\cdot
				\begin{pmatrix}
					1 & x_3 & z_3 \\ 0 & 1 & y_3 \\ 0 & 0 & 1
				\end{pmatrix}
				\]
				\[=\begin{pmatrix}
					1 & x_1+x_2 & x_1y_2+z_1+z_2 \\ 0 & 1 & y_1+y_2 \\ 0 & 0 & 1
				\end{pmatrix}
				\cdot
				\begin{pmatrix}
					1 & x_3 & z_3 \\ 0 & 1 & y_3 \\ 0 & 0 & 1
				\end{pmatrix}
				\]
				\[=
				\begin{pmatrix}
					1 & x_1+x_2+x_3 & x_1y_2 + x_1y_3 + x_2y_3 + z_1+z_2+z_3 \\ 0 & 1 & y_1+y_2+y_3 \\ 0 & 0 & 1
				\end{pmatrix}\]
				and
				\[
				\begin{pmatrix}
					1 & x_1 & z_1 \\ 0 & 1 & y_1 \\ 0 & 0 & 1
				\end{pmatrix}
				\cdot
				\left(
				\begin{pmatrix}
					1 & x_2 & z_2 \\ 0 & 1 & y_2 \\ 0 & 0 & 1
				\end{pmatrix}
				\cdot
				\begin{pmatrix}
					1 & x_3 & z_3 \\ 0 & 1 & y_3 \\ 0 & 0 & 1
				\end{pmatrix}
				\right)
				\]
				\[=				\begin{pmatrix}
					1 & x_1 & z_1 \\ 0 & 1 & y_1 \\ 0 & 0 & 1
				\end{pmatrix}
				\cdot
				\begin{pmatrix}
					1 & x_2 + x_3 & x_2y_3 + z_2 + z_3 \\ 0 & 1 & y_2 + y_3 \\ 0 & 0 & 1
				\end{pmatrix}
				\]
				\[=
				\begin{pmatrix}
					1 & x_1+x_2+x_3 & x_1y_2 + x_1y_3 + x_2y_3 + z_1+z_2+z_3 \\ 0 & 1 & y_1+y_2+y_3 \\ 0 & 0 & 1
				\end{pmatrix}\]
				and so we have associativity.
			\end{itemize}
			Therefore $(\mathcal{G},\cdot)$ is a group. It is not Abelian though. We can see this from observing that
			\[
			\begin{pmatrix}
				1 & 1 & 1 \\ 0 & 1 & 1 \\ 0 & 0 & 1
			\end{pmatrix}
			\cdot
			\begin{pmatrix}
				1 & 1 & 1 \\ 0 & 1 & 0 \\ 0 & 0 & 1
			\end{pmatrix}
			=
			\begin{pmatrix}
				1 & 2 & 2 \\ 0 & 1 & 1 \\ 0 & 0 & 1
			\end{pmatrix}
			\]
			and
			\[
			\begin{pmatrix}
				1 & 1 & 1 \\ 0 & 1 & 0 \\ 0 & 0 & 1
			\end{pmatrix}
			\cdot
			\begin{pmatrix}
				1 & 1 & 1 \\ 0 & 1 & 1 \\ 0 & 0 & 1
			\end{pmatrix}
			=
			\begin{pmatrix}
				1 & 2 & 3 \\ 0 & 1 & 1 \\ 0 & 0 & 1
			\end{pmatrix}
			\]
		\end{answered}
		
		\item
		\begin{answered}
			The first product is not computable since the column count of the first matrix is not equal to the row count of the second. All the other products are valid. I will not compute them here.
		\end{answered}
		
		\item
		\begin{answered}
			We could just ask a linear equation solver to do this for us, but I think that the point of this question is to understand the solving process. In each case we use row operations to put the "query matrix" into echelon row form. Note that we can combine the ability to multiply rows by non-zero constants and adding a row to another row to simply add a non-zero multiple of a row to a different row.\\
			\\
			a. We need to solve
			\[\begin{pmatrix}
				1 & 1 & -1 & -1\\
				2 & 5 & -7 & -5\\
				2 & -1 & 1 & 3\\
				5 & 2 & -4 & 2
			\end{pmatrix}\textbf{x}
			=
			\begin{pmatrix}
				1\\
				-2\\
				4\\
				6
			\end{pmatrix}\]
			We add multiples of row 1 to all other rows in order to force as many zeros as possible in the first column. giving
				\[\begin{pmatrix}
				1 & 1 & -1 & -1\\
				0 & 3 & -5 & -3\\
				0 & -3 & 3 & 5\\
				0 & -3 & 1 & 7
			\end{pmatrix}\textbf{x}
			=
			\begin{pmatrix}
				1\\
				-4\\
				2\\
				1
			\end{pmatrix}\]
			We repeat for row 2 and the second column:
			\[\begin{pmatrix}
				1 & 1 & -1 & -1\\
				0 & 3 & -5 & -3\\
				0 & 0 & -2 & 2\\
				0 & 0 & -4 & 4
			\end{pmatrix}\textbf{x}
			=
			\begin{pmatrix}
				1\\
				-4\\
				-2\\
				-3
			\end{pmatrix}\]
			and then row 3 and the third column:
			\[\begin{pmatrix}
				1 & 1 & -1 & -1\\
				0 & 3 & -5 & -3\\
				0 & 0 & -2 & 2\\
				0 & 0 & 0 & 0
			\end{pmatrix}\textbf{x}
			=
			\begin{pmatrix}
				1\\
				-4\\
				-2\\
				1
			\end{pmatrix}\]
			Understandably, $0=1$ has no solutions, so there are no solutions to this equation.
			
			b. We need to solve
			\[\begin{pmatrix}
				1 & -1 & 0 & 0 & 1 \\
				1 & 1 & 0 & -3 & 0 \\
				2 & -1 & 0 & 1 & -1 \\
				-1 & 2 & 0 & -2 & -1
			\end{pmatrix}
			\textbf{x}=
			\begin{pmatrix}
				3\\
				6\\
				5\\
				1
			\end{pmatrix}
			\]
			Again we do the whole "row reduction" thing. We add multiples of the first row the other rows in order to make a bunch of zeroes in the first column:
			\[\begin{pmatrix}
				1 & -1 & 0 & 0 & 1 \\
				0 & 2 & 0 & -3 & -1 \\
				0 & 1 & 0 & 1 & -3 \\
				0 & 1 & 0 & -2 & 0
			\end{pmatrix}
			\textbf{x}=
			\begin{pmatrix}
				3\\
				3\\
				-1\\
				4
			\end{pmatrix}
			\]
			Then we swap the second and third rows:
			\[\begin{pmatrix}
				1 & -1 & 0 & 0 & 1 \\
				0 & 1 & 0 & 1 & -3 \\
				0 & 2 & 0 & -3 & -1 \\
				0 & 1 & 0 & -2 & 0
			\end{pmatrix}
			\textbf{x}=
			\begin{pmatrix}
				3\\
				-1\\
				3\\
				4
			\end{pmatrix}
			\]
			Then we use the second row to introduce zeros into the second column:
			\[\begin{pmatrix}
				1 & -1 & 0 & 0 & 1 \\
				0 & 1 & 0 & 1 & -3 \\
				0 & 0 & 0 & -5 & 5 \\
				0 & 0 & 0 & -3 & 3
			\end{pmatrix}
			\textbf{x}=
			\begin{pmatrix}
				3\\
				-1\\
				5\\
				5
			\end{pmatrix}
			\]
			Multiply the third row by 3 and the last row by 5:
			\[\begin{pmatrix}
				1 & -1 & 0 & 0 & 1 \\
				0 & 1 & 0 & 1 & -3 \\
				0 & 0 & 0 & -15 & 15 \\
				0 & 0 & 0 & -15 & 15
			\end{pmatrix}
			\textbf{x}=
			\begin{pmatrix}
				3\\
				-1\\
				15\\
				25
			\end{pmatrix}
			\]
			and then subtract the third row from the 4th to give
						\[\begin{pmatrix}
				1 & -1 & 0 & 0 & 1 \\
				0 & 1 & 0 & 1 & -3 \\
				0 & 0 & 0 & -15 & 15 \\
				0 & 0 & 0 & 0 & 0
			\end{pmatrix}
			\textbf{x}=
			\begin{pmatrix}
				3\\
				-1\\
				15\\
				10
			\end{pmatrix}
			\]
			Therefore any solution to this equation would require $10=0$, and thus there are no solutions.
		\end{answered}
		
		\item
		\begin{answered}
			We need to solve 
			\[\begin{pmatrix}
				0 & 1 & 0 & 0 & 1 & 0 \\
				0 & 0 & 0 & 1 & 1 & 0 \\
				0 & 1 & 0 & 0 & 0 & 1 \\
			\end{pmatrix}
			\textbf{x}
			=
			\begin{pmatrix}
				2\\
				-1\\
				1
			\end{pmatrix}
			\]
			We can pretty straightforwardly subtract the first row from the third, giving
			\[\begin{pmatrix}
				0 & 1 & 0 & 0 & 1 & 0 \\
				0 & 0 & 0 & 1 & 1 & 0 \\
				0 & 0 & 0 & 0 & -1 & 1 \\
			\end{pmatrix}
			\textbf{x}
			=
			\begin{pmatrix}
				2\\
				-1\\
				-1
			\end{pmatrix}
			\]
			Dealing with inhomogeneity is annoying though, so a simpler practice would be to solve the homogeneous
			\[\begin{pmatrix}
				0 & 1 & 0 & 0 & 1 & 0 \\
				0 & 0 & 0 & 1 & 1 & 0 \\
				0 & 0 & 0 & 0 & -1 & 1 \\
			\end{pmatrix}
			\textbf{x}
			=
			\textbf{0}\]
			It doesn't take too much imagination here to see that the vectors
			\[\begin{pmatrix}
				1 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0
			\end{pmatrix},
			\begin{pmatrix}
				0 \\ 0 \\ 1 \\ 0 \\ 0 \\ 0
			\end{pmatrix},
			\begin{pmatrix}
				0 \\ -1 \\ 0 \\ -1 \\ 1 \\ 1
			\end{pmatrix}
			\]
			are linearly independent and lie in the kernel of this matrix
			It also doesn't take too much imagination to see that
			\[\begin{pmatrix}
				0 \\ 1 \\ 0 \\ 0 \\ 0 \\ 0
			\end{pmatrix},
			\begin{pmatrix}
				0 \\ 0 \\ 0 \\ 1 \\ 0 \\ 0
			\end{pmatrix},
			\begin{pmatrix}
				0 \\ 0 \\ 0 \\ 0 \\ 0 \\ 1
			\end{pmatrix}
			\]
			are linearly independent, and that the span of their images under  $\textbf{A}$ is all of $\mathbb{R}^3$. Therefore by rank-nullity theorem the kernel of $A$ is exactly
			\[\text{span}\left(
			\begin{pmatrix}
				1 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0
			\end{pmatrix},
			\begin{pmatrix}
				0 \\ 0 \\ 1 \\ 0 \\ 0 \\ 0
			\end{pmatrix},
			\begin{pmatrix}
				0 \\ -1 \\ 0 \\ -1 \\ 1 \\ 1
			\end{pmatrix}
			\right)\]
			Now that we have solved the homogenous equation, we need a specific solution to 
			\[\begin{pmatrix}
				0 & 1 & 0 & 0 & 1 & 0 \\
				0 & 0 & 0 & 1 & 1 & 0 \\
				0 & 0 & 0 & 0 & -1 & 1 \\
			\end{pmatrix}
			\textbf{x}
			=
			\begin{pmatrix}
				2\\
				-1\\
				-1
			\end{pmatrix}
			\]
			in order to get our general solution. We can see from our construction of a basis of $\text{Im}(\textbf{A})$ that
			\[
			\begin{pmatrix}
				0 \\ 2 \\ 0 \\ -1 \\ 0 \\ -1
			\end{pmatrix}
			\]
			is such a solution. Therefore we express the general solution as
			\[\left\{
			\begin{pmatrix}
				0 \\ 2 \\ 0 \\ -1 \\ 0 \\ -1
			\end{pmatrix} + \textbf{y},
			\textbf{y}\in
			\text{span}\left(
			\begin{pmatrix}
				1 \\ 0 \\ 0 \\ 0 \\ 0 \\ 0
			\end{pmatrix},
			\begin{pmatrix}
				0 \\ 0 \\ 1 \\ 0 \\ 0 \\ 0
			\end{pmatrix},
			\begin{pmatrix}
				0 \\ -1 \\ 0 \\ -1 \\ 1 \\ 1
			\end{pmatrix}
			\right)
			\right\}
			\]
			
		\end{answered}
		
		\item 
		\begin{answered}
			Note that both of the equations posed are linear, so we can combine them into a single linear system describing our three unknowns. This is a little fiddly so I will do so in several separate steps.\\
			\\
			We see that
			\[\textbf{Ax}=12\textbf{x}\]
			rearranges to
			\[(\textbf{A}-12\textbf{I})\textbf{x} = \textbf{0}\]
			Our second requirement can be restated as
			\[\begin{pmatrix}
				1 & 1 & 1
			\end{pmatrix}
			\textbf{x} = 1\]
			We can combine these into a single linear system, giving
			\[
			\begin{pmatrix}
				1 & 1 & 1 \\
				-6 & 4 & 3 \\
				6 & -12 & 9 \\
				0 & 8 & -12 \\
			\end{pmatrix}
							\textbf{x}
			=
			\begin{pmatrix}
				1 \\ 0 \\ 0 \\ 0
			\end{pmatrix}
			\]
			We will use Gaussian elimination to solve this. Reducing the first column:
			\[
			\begin{pmatrix}
				1 & 1 & 1 \\
				0 & 10 & 9 \\
				0 & -18 & 3 \\
				0 & 8 & -12 \\
			\end{pmatrix}
			\textbf{x}
			=
			\begin{pmatrix}
				1 \\ 6 \\ -6 \\ 0
			\end{pmatrix}
			\]
			Swapping rows 2 and 4, then dividing row 2 through by 4:
			\[
			\begin{pmatrix}
				1 & 1 & 1 \\
				0 & 2 & -3 \\
				0 & -18 & 3 \\
				0 & 10 & 9 \\
			\end{pmatrix}
			\textbf{x}
			=
			\begin{pmatrix}
				1 \\ 0 \\ -6 \\ 6
			\end{pmatrix}
			\]
			Now we reduce column 2:
						\[
			\begin{pmatrix}
				1 & 1 & 1 \\
				0 & 2 & -3 \\
				0 & 0 & -24 \\
				0 & 0 & 24 \\
			\end{pmatrix}
			\textbf{x}
			=
			\begin{pmatrix}
				1 \\ 0 \\ -6 \\ 6
			\end{pmatrix}
			\]
			And then add the 3rd row to the 4th to remove it altogether:
			\[
			\begin{pmatrix}
				1 & 1 & 1 \\
				0 & 2 & -3 \\
				0 & 0 & -24 \\
				0 & 0 & 0 \\
			\end{pmatrix}
			\textbf{x}
			=
			\begin{pmatrix}
				1 \\ 0 \\ -6 \\ 0
			\end{pmatrix}
			\]
			Or more succinctly:
			\[
			\begin{pmatrix}
				1 & 1 & 1 \\
				0 & 2 & -3 \\
				0 & 0 & -24 \\
			\end{pmatrix}
			\textbf{x}
			=
			\begin{pmatrix}
				1 \\ 0 \\ -6
			\end{pmatrix}
			\]
			The matrix on the left is upper triangular, and so we can clearly see that the determinant is non-zero, meaning that the matrix is invertible. Computing the inverse is not mathematically interesting so I will let the computer do the work, revealing the unique solution to our equation as
			\[\textbf{x}
			=
			\begin{pmatrix}
				1 & 1 & 1 \\
				0 & 2 & -3 \\
				0 & 0 & -24 \\
			\end{pmatrix}^{-1}
			\begin{pmatrix}
				1 \\ 0 \\ -6
			\end{pmatrix}
			=
			\frac{1}{8}\cdot
			\begin{pmatrix}
				3 \\ 3 \\ 2
			\end{pmatrix}\]
		\end{answered}
		
		\item
		\begin{answered}
			a. The rows of this matrix are not independent - the second row is the arithmetic average of the other two. Therefore the matrix is non-invertible.
			
			b. This one is not quite so obvious from the outset. We could easily find out whether or not the determinant is zero by plugging it into Wolfram Alpha, but let's do this manually instead. Row operations do not change the row space of the matrix, and we will use this to our advantage.
			
			We start by adding multiples of the first row to everything to "zero out" the first column:
			
			\[\begin{pmatrix}
				1 & 0 & 1 & 0 \\
				0 & 1 & 1 & 0 \\
				0 & 1 & -1 & 1 \\
				0 & 1 & 0 & 0 \\
			\end{pmatrix}
			\]
			
			Now we do the same for the second row and column:
			
			\[\begin{pmatrix}
				1 & 0 & 1 & 0 \\
				0 & 1 & 1 & 0 \\
				0 & 0 & -2 & 1 \\
				0 & 0 & -1 & 0 \\
			\end{pmatrix}
			\]
			
			Now we switch rows 3 and 4:
			
			\[\begin{pmatrix}
				1 & 0 & 1 & 0 \\
				0 & 1 & 1 & 0 \\
				0 & 0 & -1 & 0 \\
				0 & 0 & -2 & 1 \\
			\end{pmatrix}
			\]
			
			And now we reduce the third column using the third row:
			
			\[\begin{pmatrix}
				1 & 0 & 1 & 0 \\
				0 & 1 & 1 & 0 \\
				0 & 0 & -1 & 0 \\
				0 & 0 & 0 & 1 \\
			\end{pmatrix}
			\]
			
			The determinant of this upper triangular matrix is -1, so it is invertible. Since the row space is unchanged, the original matrix was also invertible.
			
			At this point I have no qualms about getting Wolfram Alpha to compute the inverse for me, since I know that it exists. Plugging constants into the lengthy formula for a 4x4 inverse is not an instructive or enjoyable exercise.
			
			Thus we find the inverse to be 
			
			\[\begin{pmatrix}
				0 & -1 & 0 & 1 \\
				-1 & 0 & 0 & 1 \\
				1 & 1 & 0 & -1 \\
				1 & 1 & 1 & -2 \\
			\end{pmatrix}\]
		\end{answered}
		
		\item 
		\begin{answered}
			a. Despite appearances, this is a vector space. Note that $f:\mathbb{R}\rightarrow\mathbb{R}$ given by $f(x)=f(x^3)$ is a surjection. Therefore we can rewrite
			\[A = \{(x,x+y,x-y)|x,y\in\mathbb{R}\}\]
			or more succinctly:
			\[A = \left\{
			x\begin{pmatrix}
				1 \\ 1 \\ 1
			\end{pmatrix}
			+			
			y\begin{pmatrix}
				0 \\ 1 \\ -1
			\end{pmatrix}
			|x,y\in\mathbb{R}
			\right\}
			\]
			which is a 2D plane through the origin and thus clearly a subspace of $\mathbb{R}^3$
			
			b. This is not a vector space. $(1,-1,0)\in B$ but $-1*(1,-1,0)=(-1,1,0)\notin B$
			
			c. This is a subspace iff $\gamma=0$. If $\gamma\neq0$ then $(0,0,0)\notin C$, and having an additive identity is a requirement of a vector space.
			
			If $\gamma=0$ then we can pick $\xi_2$ and $\xi_3$ freely, at which point $\xi_1$ is uniquely determined as $2\xi_2-3\xi_3$. Thus we can write $C$ as
			\[A = \left\{
			x\begin{pmatrix}
				2 \\ 1 \\ 0
			\end{pmatrix}
			+			
			y\begin{pmatrix}
				-3 \\ 0 \\ 1
			\end{pmatrix}
			|x,y\in\mathbb{R}
			\right\}
			\]
			which is a plane through the origin. $C$ is a subspace in this case.
			
			d. $D$ is not a subspace since it is not closed under scalar multiplication in $\mathbb{R}$. $(1,1,1)\in D$, but $\frac{1}{2}(1,1,1)=(\frac{1}{2},\frac{1}{2},\frac{1}{2})\notin D$
		\end{answered}
		\item 
		\begin{answered}
			a. The vectors are linearly dependent: $x_3-2x_1=x_2$
			b. These vectors are linearly independent. Suppose that we have
			\[a_1x_1+a_2x_2+a_3x_3=0\]
			Looking at dimension 3, we see that necessarily $a_1=0$. Then, looking at dimension 2, we see that this forces $a_2=0$, which also forces $a_3=0$.
		\end{answered}
		\item
		\begin{answered}
			We want to solve
			\[a_1x_1+a_2x_2+a_3x_3=y\]
			which we can rewrite as
			\[
			\begin{pmatrix}
				1 & 1 & 2 \\
				1 & 2 & -1 \\
				1 & 3 & 1
			\end{pmatrix}
			\begin{pmatrix}
				a_1 \\ a_2 \\ a_3
			\end{pmatrix}
			=
			y
			\]
			If we check we can see that the matrix on the left is invertible. We can therefore compute its inverse and write
			\[
			\begin{pmatrix}
				a_1 \\ a_2 \\ a_3
			\end{pmatrix}
			=
			\frac{1}{5}
			\begin{pmatrix}
				5 &  5 & -5 \\
				-2 & -1 &  3 \\
				1 & -2 &  1 \\
			\end{pmatrix}
			y
			=
			\begin{pmatrix}
				-6 \\ 3 \\ 2
			\end{pmatrix}
			\]
			Therefore we have
			\[-6x_1+3x_2+2x_3=y\]
		\end{answered}
		\item
		\begin{answered}
			Suppose we want to find the generic form of a point $x\in U_1\cap U_2$. Then we can write
			\[x = 
			\begin{pmatrix}
				1 &  2 & -1 \\
				1 & -1 &  1 \\
				-3 &  0 & -1 \\
				1 & -1 &  1 \\
			\end{pmatrix}
			\begin{pmatrix}
				a_1 \\ a_2 \\ a_3
			\end{pmatrix}
			=	
			\begin{pmatrix}
				-1 &  2 & -3 \\
				-2 & -2 &  6 \\
				2 &  0 & -2 \\
				1 &  0 & -1 \\
			\end{pmatrix}
			\begin{pmatrix}
				b_1 \\ b_2 \\ b_3
			\end{pmatrix}
			\]
			for some $a_1,a_2,a_3,b_1,b_2,b_3$. We are not however free to pick these 6 values independently however we want - we do actually need the above equality to hold.
			
			So we need
			\[
			\begin{pmatrix}
				1 &  2 & -1 \\
				1 & -1 &  1 \\
				-3 &  0 & -1 \\
				1 & -1 &  1 \\
			\end{pmatrix}
			\begin{pmatrix}
				a_1 \\ a_2 \\ a_3
			\end{pmatrix}
			=	
			\begin{pmatrix}
				-1 &  2 & -3 \\
				-2 & -2 &  6 \\
				2 &  0 & -2 \\
				1 &  0 & -1 \\
			\end{pmatrix}
			\begin{pmatrix}
				b_1 \\ b_2 \\ b_3
			\end{pmatrix}
			\]
			which we can rewrite as
			\[
			\begin{pmatrix}
				1 &  2 & -1 & -1 &  2 & -3  \\
				1 & -1 &  1  & -2 & -2 &  6\\
				-3 &  0 & -1 & 2 &  0 & -2 \\
				1 & -1 &  1  & 1 &  0 & -1\\
			\end{pmatrix}
			\begin{pmatrix}
				a_1 \\ a_2 \\ a_3 \\ b_1 \\ b_2 \\ b_3
			\end{pmatrix}
			= 0
			\]
			We can now solve this by Gaussian elimination. We reduce column 1 with multiples of the first row:
			\[
			\begin{pmatrix}
				1 &  2 & -1 & -1 &  2 & -3  \\
				0 & -3 &  2  & -1 & -4 &  9\\
				0 &  6 & -4 & -1 &  6 & -11 \\
				0 & -3 &  2  & 2 &  -2 & 2\\
			\end{pmatrix}
			\begin{pmatrix}
				a_1 \\ a_2 \\ a_3 \\ b_1 \\ b_2 \\ b_3
			\end{pmatrix}
			= 0
			\]
			and now we reduce column 2 with multiples of the second row:
			\[
			\begin{pmatrix}
				1 &  2 & -1 & -1 &  2 & -3  \\
				0 & -3 & 2 & -1 & -4 &  9\\
				0 &  0 & 0 & -3 &  2 & -7 \\
				0 &  0 & 0 & 3 &  2 & -7\\
			\end{pmatrix}
			\begin{pmatrix}
				a_1 \\ a_2 \\ a_3 \\ b_1 \\ b_2 \\ b_3
			\end{pmatrix}
			= 0
			\]
			and now we reduce column 4 with multiples of the third row:
			\[
			\begin{pmatrix}
				1 &  2 & -1 & -1 &  2 & -3  \\
				0 & -3 & 2 & -1 & -4 &  9\\
				0 &  0 & 0 & -3 &  2 & -7 \\
				0 &  0 & 0 & 0 &  4 & -14\\
			\end{pmatrix}
			\begin{pmatrix}
				a_1 \\ a_2 \\ a_3 \\ b_1 \\ b_2 \\ b_3
			\end{pmatrix}
			= 0
			\]
			We now work out the complete 
		\end{answered}
	\end{QandA}
\end{document}